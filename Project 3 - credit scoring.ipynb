{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5ad3186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from time import time\n",
    "import xgboost as xgb\n",
    "from hyperopt import Trials, hp, fmin, tpe, STATUS_OK\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import OneClassSVM\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d67ef194",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet('./parquets/P03_train.pq')\n",
    "df_test = pd.read_parquet('./parquets/P03_test.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83184fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Feature    Chi-squared        p-value\n",
      "0                           id  175000.000000   4.988761e-01\n",
      "1                         flag  174966.717465   0.000000e+00\n",
      "13  pre_loans_credit_cost_rate    1022.184686  3.184142e-211\n",
      "31                  enc_paym_1     836.606620  4.976220e-181\n",
      "32                  enc_paym_2     816.479351  1.153998e-176\n",
      "..                         ...            ...            ...\n",
      "18                 pre_loans90       6.484555   9.027360e-02\n",
      "58       enc_loans_account_cur       4.419185   1.097453e-01\n",
      "60                 fclose_flag       4.116843   4.245823e-02\n",
      "11     pre_loans_total_overdue       0.000000   1.000000e+00\n",
      "17               pre_loans6090       0.000000   1.000000e+00\n",
      "\n",
      "[61 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Assuming you have your dataset loaded into 'df_train' (a pandas DataFrame)\n",
    "# and the target variable is 'target_column_name'\n",
    "\n",
    "# Create a contingency table for each feature with the target variable\n",
    "contingency_tables = []\n",
    "for feature_column in df_train.columns:\n",
    "    contingency_table = pd.crosstab(df_train[feature_column], df_train['flag'])\n",
    "    contingency_tables.append(contingency_table)\n",
    "\n",
    "# Calculate chi-squared statistic, p-value, degrees of freedom, and expected frequencies\n",
    "feature_importance_results = []\n",
    "for contingency_table in contingency_tables:\n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "    feature_importance_results.append({'Feature': contingency_table.index.name, 'Chi-squared': chi2, 'p-value': p_value})\n",
    "\n",
    "# Convert the results to a DataFrame for easy visualization\n",
    "results_df = pd.DataFrame(feature_importance_results)\n",
    "\n",
    "# Sort the results based on chi-squared values in descending order\n",
    "results_df = results_df.sort_values(by='Chi-squared', ascending=False)\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "522aff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_features = results_df[results_df['p-value'] < 0.05]['Feature'].tolist()\n",
    "\n",
    "df = df_train[significant_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d77a7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('flag', axis=1)\n",
    "y = df['flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b6a9df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0b97b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_val_std = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25d86dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 15 # Choose the number of principal components (you can experiment with different values)\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_val_pca = pca.transform(X_val_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b72557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs': -1,\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log = True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),\n",
    "        'scale_pos_weight': len(y_train[y_train == 0]) / len(y_train[y_train == 1])        \n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "\n",
    "    # Use cross-validation to evaluate the model's performance\n",
    "    score = cross_val_score(model, X_train_pca, y_train, n_jobs=-1, cv=3, scoring='precision').mean()\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80e1c144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-01 22:17:26,217] A new study created in memory with name: no-name-7d73b8e2-a4a1-44e5-8da5-6d7b819aeea9\n",
      "[I 2023-08-01 22:17:34,764] Trial 0 finished with value: 0.0683966347232075 and parameters: {'num_leaves': 44, 'learning_rate': 0.07969454818643935, 'n_estimators': 746, 'min_child_samples': 60}. Best is trial 0 with value: 0.0683966347232075.\n",
      "[I 2023-08-01 22:17:36,715] Trial 1 finished with value: 0.0 and parameters: {'num_leaves': 24, 'learning_rate': 0.002051110418843397, 'n_estimators': 105, 'min_child_samples': 87}. Best is trial 0 with value: 0.0683966347232075.\n",
      "[I 2023-08-01 22:17:38,242] Trial 2 finished with value: 0.06498488189474785 and parameters: {'num_leaves': 64, 'learning_rate': 0.02607024758370768, 'n_estimators': 69, 'min_child_samples': 97}. Best is trial 0 with value: 0.0683966347232075.\n",
      "[I 2023-08-01 22:17:43,190] Trial 3 finished with value: 0.0 and parameters: {'num_leaves': 85, 'learning_rate': 0.0026587543983272706, 'n_estimators': 222, 'min_child_samples': 19}. Best is trial 0 with value: 0.0683966347232075.\n",
      "[I 2023-08-01 22:17:48,200] Trial 4 finished with value: 0.05444874767108802 and parameters: {'num_leaves': 37, 'learning_rate': 0.01120760621186057, 'n_estimators': 460, 'min_child_samples': 30}. Best is trial 0 with value: 0.0683966347232075.\n",
      "[I 2023-08-01 22:17:53,958] Trial 5 finished with value: 0.0 and parameters: {'num_leaves': 65, 'learning_rate': 0.0019010245319870357, 'n_estimators': 327, 'min_child_samples': 37}. Best is trial 0 with value: 0.0683966347232075.\n",
      "[I 2023-08-01 22:17:56,930] Trial 6 finished with value: 0.05796609066384891 and parameters: {'num_leaves': 51, 'learning_rate': 0.037183641805732096, 'n_estimators': 239, 'min_child_samples': 52}. Best is trial 0 with value: 0.0683966347232075.\n",
      "[I 2023-08-01 22:18:06,913] Trial 7 finished with value: 0.0 and parameters: {'num_leaves': 63, 'learning_rate': 0.001238513729886093, 'n_estimators': 627, 'min_child_samples': 18}. Best is trial 0 with value: 0.0683966347232075.\n",
      "[I 2023-08-01 22:18:13,209] Trial 8 finished with value: 0.06114721713388493 and parameters: {'num_leaves': 15, 'learning_rate': 0.07902619549708234, 'n_estimators': 968, 'min_child_samples': 81}. Best is trial 0 with value: 0.0683966347232075.\n",
      "[I 2023-08-01 22:18:21,958] Trial 9 finished with value: 0.13531892309486868 and parameters: {'num_leaves': 37, 'learning_rate': 0.0015679933916723015, 'n_estimators': 700, 'min_child_samples': 45}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:18:38,304] Trial 10 finished with value: 0.061165501567062436 and parameters: {'num_leaves': 96, 'learning_rate': 0.005338943774556119, 'n_estimators': 861, 'min_child_samples': 2}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:18:46,337] Trial 11 finished with value: 0.055145662860506865 and parameters: {'num_leaves': 40, 'learning_rate': 0.00819523089277392, 'n_estimators': 699, 'min_child_samples': 61}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:18:53,072] Trial 12 finished with value: 0.06652044040289748 and parameters: {'num_leaves': 36, 'learning_rate': 0.09190992805196459, 'n_estimators': 762, 'min_child_samples': 70}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:19:00,318] Trial 13 finished with value: 0.06246662341147879 and parameters: {'num_leaves': 52, 'learning_rate': 0.0040324591380050895, 'n_estimators': 508, 'min_child_samples': 48}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:19:10,047] Trial 14 finished with value: 0.0 and parameters: {'num_leaves': 24, 'learning_rate': 0.0010371310165871647, 'n_estimators': 832, 'min_child_samples': 65}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:19:17,111] Trial 15 finished with value: 0.05651535610536056 and parameters: {'num_leaves': 45, 'learning_rate': 0.012149740774713978, 'n_estimators': 625, 'min_child_samples': 45}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:19:31,636] Trial 16 finished with value: 0.06872969914569134 and parameters: {'num_leaves': 78, 'learning_rate': 0.016801442995035186, 'n_estimators': 989, 'min_child_samples': 73}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:19:50,102] Trial 17 finished with value: 0.05895299638685895 and parameters: {'num_leaves': 80, 'learning_rate': 0.0041437902139372824, 'n_estimators': 1000, 'min_child_samples': 76}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:20:05,177] Trial 18 finished with value: 0.06889286866084406 and parameters: {'num_leaves': 81, 'learning_rate': 0.017126351622902693, 'n_estimators': 878, 'min_child_samples': 100}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:20:21,792] Trial 19 finished with value: 0.06211406569303509 and parameters: {'num_leaves': 98, 'learning_rate': 0.006109916983407157, 'n_estimators': 868, 'min_child_samples': 100}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:20:31,433] Trial 20 finished with value: 0.058457830016702496 and parameters: {'num_leaves': 70, 'learning_rate': 0.0075000179163697694, 'n_estimators': 581, 'min_child_samples': 30}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:20:44,978] Trial 21 finished with value: 0.06847083951794346 and parameters: {'num_leaves': 79, 'learning_rate': 0.018693955373045724, 'n_estimators': 916, 'min_child_samples': 87}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:20:57,691] Trial 22 finished with value: 0.06727218363997332 and parameters: {'num_leaves': 86, 'learning_rate': 0.01471692914010428, 'n_estimators': 793, 'min_child_samples': 87}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:21:11,236] Trial 23 finished with value: 0.06695333470333265 and parameters: {'num_leaves': 71, 'learning_rate': 0.019263008322842785, 'n_estimators': 925, 'min_child_samples': 74}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:21:23,756] Trial 24 finished with value: 0.06147064753287459 and parameters: {'num_leaves': 89, 'learning_rate': 0.007859747283144711, 'n_estimators': 696, 'min_child_samples': 52}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:21:37,784] Trial 25 finished with value: 0.06322499007173525 and parameters: {'num_leaves': 75, 'learning_rate': 0.00966431440110771, 'n_estimators': 898, 'min_child_samples': 96}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:21:47,477] Trial 26 finished with value: 0.06715794098509952 and parameters: {'num_leaves': 56, 'learning_rate': 0.03339623474249062, 'n_estimators': 808, 'min_child_samples': 41}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:22:03,086] Trial 27 finished with value: 0.06863446179160819 and parameters: {'num_leaves': 91, 'learning_rate': 0.014009469654477934, 'n_estimators': 1000, 'min_child_samples': 58}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:22:10,972] Trial 28 finished with value: 0.05796809313028867 and parameters: {'num_leaves': 29, 'learning_rate': 0.0033739662416512927, 'n_estimators': 703, 'min_child_samples': 68}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:22:21,654] Trial 29 finished with value: 0.05703288827487798 and parameters: {'num_leaves': 58, 'learning_rate': 0.004991234041800157, 'n_estimators': 739, 'min_child_samples': 80}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:22:27,415] Trial 30 finished with value: 0.05792130563700912 and parameters: {'num_leaves': 46, 'learning_rate': 0.006429002184975099, 'n_estimators': 410, 'min_child_samples': 58}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:22:44,650] Trial 31 finished with value: 0.06999846545933491 and parameters: {'num_leaves': 92, 'learning_rate': 0.013950608149532988, 'n_estimators': 995, 'min_child_samples': 57}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:23:01,534] Trial 32 finished with value: 0.06596936293087456 and parameters: {'num_leaves': 100, 'learning_rate': 0.01026022246454646, 'n_estimators': 950, 'min_child_samples': 36}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:23:17,018] Trial 33 finished with value: 0.06987618024184021 and parameters: {'num_leaves': 93, 'learning_rate': 0.01880216208763009, 'n_estimators': 873, 'min_child_samples': 91}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:23:32,453] Trial 34 finished with value: 0.07195393448638716 and parameters: {'num_leaves': 93, 'learning_rate': 0.02224157385544136, 'n_estimators': 857, 'min_child_samples': 94}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:23:46,610] Trial 35 finished with value: 0.07189867273194123 and parameters: {'num_leaves': 96, 'learning_rate': 0.022876919659253644, 'n_estimators': 812, 'min_child_samples': 89}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:23:59,676] Trial 36 finished with value: 0.07002197418719076 and parameters: {'num_leaves': 85, 'learning_rate': 0.023975597637521825, 'n_estimators': 777, 'min_child_samples': 92}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:24:09,253] Trial 37 finished with value: 0.0689275858528069 and parameters: {'num_leaves': 86, 'learning_rate': 0.024458935720733314, 'n_estimators': 600, 'min_child_samples': 94}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:24:13,893] Trial 38 finished with value: 0.055717248187427994 and parameters: {'num_leaves': 15, 'learning_rate': 0.04080610498372154, 'n_estimators': 662, 'min_child_samples': 90}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:24:28,929] Trial 39 finished with value: 0.08819565501902772 and parameters: {'num_leaves': 84, 'learning_rate': 0.0016746442224753028, 'n_estimators': 760, 'min_child_samples': 82}. Best is trial 9 with value: 0.13531892309486868.\n",
      "[I 2023-08-01 22:24:40,058] Trial 40 finished with value: 0.1399974150958403 and parameters: {'num_leaves': 95, 'learning_rate': 0.0018304110063499563, 'n_estimators': 550, 'min_child_samples': 82}. Best is trial 40 with value: 0.1399974150958403.\n",
      "[I 2023-08-01 22:24:50,598] Trial 41 finished with value: 0.09455128205128205 and parameters: {'num_leaves': 100, 'learning_rate': 0.0018236222423584224, 'n_estimators': 489, 'min_child_samples': 82}. Best is trial 40 with value: 0.1399974150958403.\n",
      "[I 2023-08-01 22:24:59,837] Trial 42 finished with value: 0.0 and parameters: {'num_leaves': 95, 'learning_rate': 0.0017834476596298415, 'n_estimators': 419, 'min_child_samples': 82}. Best is trial 40 with value: 0.1399974150958403.\n",
      "[I 2023-08-01 22:25:12,139] Trial 43 finished with value: 0.10289879217718216 and parameters: {'num_leaves': 99, 'learning_rate': 0.0021329274795713633, 'n_estimators': 551, 'min_child_samples': 82}. Best is trial 40 with value: 0.1399974150958403.\n",
      "[I 2023-08-01 22:25:16,655] Trial 44 finished with value: 0.13173296562482592 and parameters: {'num_leaves': 10, 'learning_rate': 0.002294067217022634, 'n_estimators': 491, 'min_child_samples': 83}. Best is trial 40 with value: 0.1399974150958403.\n",
      "[I 2023-08-01 22:25:21,364] Trial 45 finished with value: 0.12698774509803923 and parameters: {'num_leaves': 12, 'learning_rate': 0.002495502788262568, 'n_estimators': 478, 'min_child_samples': 78}. Best is trial 40 with value: 0.1399974150958403.\n",
      "[I 2023-08-01 22:25:25,925] Trial 46 finished with value: 0.08096995564662655 and parameters: {'num_leaves': 10, 'learning_rate': 0.0024402355864990375, 'n_estimators': 550, 'min_child_samples': 65}. Best is trial 40 with value: 0.1399974150958403.\n",
      "[I 2023-08-01 22:25:29,903] Trial 47 finished with value: 0.0 and parameters: {'num_leaves': 22, 'learning_rate': 0.001425344203188075, 'n_estimators': 327, 'min_child_samples': 22}. Best is trial 40 with value: 0.1399974150958403.\n",
      "[I 2023-08-01 22:25:35,281] Trial 48 finished with value: 0.14232242852932508 and parameters: {'num_leaves': 27, 'learning_rate': 0.002318396641830523, 'n_estimators': 441, 'min_child_samples': 77}. Best is trial 48 with value: 0.14232242852932508.\n",
      "[I 2023-08-01 22:25:39,784] Trial 49 finished with value: 0.037037037037037035 and parameters: {'num_leaves': 33, 'learning_rate': 0.0027423091837205323, 'n_estimators': 333, 'min_child_samples': 76}. Best is trial 48 with value: 0.14232242852932508.\n",
      "[I 2023-08-01 22:25:44,878] Trial 50 finished with value: 0.0 and parameters: {'num_leaves': 20, 'learning_rate': 0.0013054976193015066, 'n_estimators': 455, 'min_child_samples': 70}. Best is trial 48 with value: 0.14232242852932508.\n",
      "[I 2023-08-01 22:25:49,526] Trial 51 finished with value: 0.12131528664734131 and parameters: {'num_leaves': 11, 'learning_rate': 0.0023210703892503704, 'n_estimators': 533, 'min_child_samples': 85}. Best is trial 48 with value: 0.14232242852932508.\n",
      "[I 2023-08-01 22:25:53,235] Trial 52 finished with value: 0.10774091627172196 and parameters: {'num_leaves': 11, 'learning_rate': 0.002463166905692217, 'n_estimators': 407, 'min_child_samples': 78}. Best is trial 48 with value: 0.14232242852932508.\n",
      "[I 2023-08-01 22:25:57,337] Trial 53 finished with value: 0.0 and parameters: {'num_leaves': 17, 'learning_rate': 0.0011081669181084708, 'n_estimators': 365, 'min_child_samples': 87}. Best is trial 48 with value: 0.14232242852932508.\n",
      "[I 2023-08-01 22:26:00,888] Trial 54 finished with value: 0.0 and parameters: {'num_leaves': 31, 'learning_rate': 0.001423701816599102, 'n_estimators': 258, 'min_child_samples': 65}. Best is trial 48 with value: 0.14232242852932508.\n",
      "[I 2023-08-01 22:26:05,402] Trial 55 finished with value: 0.1483126691047483 and parameters: {'num_leaves': 14, 'learning_rate': 0.002128653997299958, 'n_estimators': 475, 'min_child_samples': 48}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:26:10,980] Trial 56 finished with value: 0.07768739475483909 and parameters: {'num_leaves': 26, 'learning_rate': 0.0028925518301325297, 'n_estimators': 474, 'min_child_samples': 45}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:26:17,136] Trial 57 finished with value: 0.0 and parameters: {'num_leaves': 40, 'learning_rate': 0.001943154677634638, 'n_estimators': 448, 'min_child_samples': 53}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:26:22,206] Trial 58 finished with value: 0.0 and parameters: {'num_leaves': 18, 'learning_rate': 0.00163461052835573, 'n_estimators': 503, 'min_child_samples': 33}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:26:24,070] Trial 59 finished with value: 0.0 and parameters: {'num_leaves': 14, 'learning_rate': 0.0021400384906266165, 'n_estimators': 166, 'min_child_samples': 46}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:26:30,259] Trial 60 finished with value: 0.06263396902460029 and parameters: {'num_leaves': 24, 'learning_rate': 0.0032032882070130255, 'n_estimators': 584, 'min_child_samples': 40}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:26:34,604] Trial 61 finished with value: 0.13263578022831216 and parameters: {'num_leaves': 10, 'learning_rate': 0.0021728722567271276, 'n_estimators': 529, 'min_child_samples': 85}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:26:40,400] Trial 62 finished with value: 0.08616118986388953 and parameters: {'num_leaves': 14, 'learning_rate': 0.002047110556334686, 'n_estimators': 636, 'min_child_samples': 73}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:26:44,869] Trial 63 finished with value: 0.0 and parameters: {'num_leaves': 20, 'learning_rate': 0.0010506029203207164, 'n_estimators': 371, 'min_child_samples': 49}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:26:51,301] Trial 64 finished with value: 0.0 and parameters: {'num_leaves': 29, 'learning_rate': 0.0015105793039586726, 'n_estimators': 523, 'min_child_samples': 78}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:26:56,043] Trial 65 finished with value: 0.0 and parameters: {'num_leaves': 17, 'learning_rate': 0.0012658067344520183, 'n_estimators': 446, 'min_child_samples': 54}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:27:01,926] Trial 66 finished with value: 0.07833193974571974 and parameters: {'num_leaves': 49, 'learning_rate': 0.0035499398358732324, 'n_estimators': 381, 'min_child_samples': 63}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:27:06,658] Trial 67 finished with value: 0.06860348411183423 and parameters: {'num_leaves': 10, 'learning_rate': 0.0028074725074072773, 'n_estimators': 562, 'min_child_samples': 71}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:27:14,857] Trial 68 finished with value: 0.07670452156517195 and parameters: {'num_leaves': 38, 'learning_rate': 0.0022480313003373437, 'n_estimators': 617, 'min_child_samples': 41}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:27:21,098] Trial 69 finished with value: 0.13265591990447323 and parameters: {'num_leaves': 13, 'learning_rate': 0.001622682182250521, 'n_estimators': 668, 'min_child_samples': 6}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:27:28,722] Trial 70 finished with value: 0.14106896249448533 and parameters: {'num_leaves': 26, 'learning_rate': 0.0015592035806748445, 'n_estimators': 660, 'min_child_samples': 18}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:27:37,060] Trial 71 finished with value: 0.13221718174556152 and parameters: {'num_leaves': 26, 'learning_rate': 0.001675627640714521, 'n_estimators': 675, 'min_child_samples': 1}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:27:44,661] Trial 72 finished with value: 0.13425939136716794 and parameters: {'num_leaves': 26, 'learning_rate': 0.0016390608308851549, 'n_estimators': 661, 'min_child_samples': 2}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:27:54,433] Trial 73 finished with value: 0.0 and parameters: {'num_leaves': 34, 'learning_rate': 0.0012375719376978896, 'n_estimators': 713, 'min_child_samples': 6}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:28:03,390] Trial 74 finished with value: 0.07522367282358085 and parameters: {'num_leaves': 27, 'learning_rate': 0.0019349564840816038, 'n_estimators': 735, 'min_child_samples': 10}. Best is trial 55 with value: 0.1483126691047483.\n",
      "[I 2023-08-01 22:28:12,706] Trial 75 finished with value: 0.16095452003641725 and parameters: {'num_leaves': 42, 'learning_rate': 0.0015440809464067967, 'n_estimators': 644, 'min_child_samples': 15}. Best is trial 75 with value: 0.16095452003641725.\n",
      "[I 2023-08-01 22:28:21,035] Trial 76 finished with value: 0.15563018837158682 and parameters: {'num_leaves': 35, 'learning_rate': 0.0015409274692677606, 'n_estimators': 647, 'min_child_samples': 13}. Best is trial 75 with value: 0.16095452003641725.\n",
      "[I 2023-08-01 22:28:30,367] Trial 77 finished with value: 0.14460017969451933 and parameters: {'num_leaves': 42, 'learning_rate': 0.0015210855095558564, 'n_estimators': 648, 'min_child_samples': 16}. Best is trial 75 with value: 0.16095452003641725.\n",
      "[I 2023-08-01 22:28:39,064] Trial 78 finished with value: 0.0 and parameters: {'num_leaves': 42, 'learning_rate': 0.001157317029395241, 'n_estimators': 602, 'min_child_samples': 18}. Best is trial 75 with value: 0.16095452003641725.\n",
      "[I 2023-08-01 22:28:48,874] Trial 79 finished with value: 0.14907922628510864 and parameters: {'num_leaves': 36, 'learning_rate': 0.001391865513374202, 'n_estimators': 715, 'min_child_samples': 24}. Best is trial 75 with value: 0.16095452003641725.\n",
      "[I 2023-08-01 22:28:59,499] Trial 80 finished with value: 0.17101851851851854 and parameters: {'num_leaves': 48, 'learning_rate': 0.0013743948836060582, 'n_estimators': 718, 'min_child_samples': 23}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:29:08,968] Trial 81 finished with value: 0.041666666666666664 and parameters: {'num_leaves': 46, 'learning_rate': 0.0014019921794247141, 'n_estimators': 637, 'min_child_samples': 22}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:29:19,317] Trial 82 finished with value: 0.1694717824371226 and parameters: {'num_leaves': 48, 'learning_rate': 0.001337010017040041, 'n_estimators': 719, 'min_child_samples': 13}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:29:30,625] Trial 83 finished with value: 0.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.0010214327593059448, 'n_estimators': 730, 'min_child_samples': 15}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:29:41,810] Trial 84 finished with value: 0.0 and parameters: {'num_leaves': 54, 'learning_rate': 0.0012131376803152115, 'n_estimators': 689, 'min_child_samples': 27}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:29:53,062] Trial 85 finished with value: 0.13052736502455967 and parameters: {'num_leaves': 43, 'learning_rate': 0.0013932240399515384, 'n_estimators': 776, 'min_child_samples': 14}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:30:03,111] Trial 86 finished with value: 0.16874699447487804 and parameters: {'num_leaves': 48, 'learning_rate': 0.0015143647436708784, 'n_estimators': 652, 'min_child_samples': 24}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:30:13,993] Trial 87 finished with value: 0.0 and parameters: {'num_leaves': 48, 'learning_rate': 0.0011220781648079536, 'n_estimators': 705, 'min_child_samples': 24}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:30:25,460] Trial 88 finished with value: 0.13589820982739165 and parameters: {'num_leaves': 40, 'learning_rate': 0.0013091542077144386, 'n_estimators': 827, 'min_child_samples': 15}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:30:37,554] Trial 89 finished with value: 0.07523166062524018 and parameters: {'num_leaves': 53, 'learning_rate': 0.001890917821388655, 'n_estimators': 758, 'min_child_samples': 10}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:30:47,995] Trial 90 finished with value: 0.09105885478942473 and parameters: {'num_leaves': 60, 'learning_rate': 0.0014558959872049443, 'n_estimators': 642, 'min_child_samples': 28}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:30:57,812] Trial 91 finished with value: 0.1245166229299619 and parameters: {'num_leaves': 38, 'learning_rate': 0.0015929761991644495, 'n_estimators': 722, 'min_child_samples': 21}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:31:07,116] Trial 92 finished with value: 0.0 and parameters: {'num_leaves': 35, 'learning_rate': 0.001182307654889626, 'n_estimators': 683, 'min_child_samples': 12}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:31:16,490] Trial 93 finished with value: 0.13524955436720143 and parameters: {'num_leaves': 43, 'learning_rate': 0.0017983310401895269, 'n_estimators': 606, 'min_child_samples': 25}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:31:23,819] Trial 94 finished with value: 0.0 and parameters: {'num_leaves': 32, 'learning_rate': 0.0015117006182895796, 'n_estimators': 578, 'min_child_samples': 19}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:31:33,837] Trial 95 finished with value: 0.0 and parameters: {'num_leaves': 45, 'learning_rate': 0.0013026890080933234, 'n_estimators': 642, 'min_child_samples': 6}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:31:42,480] Trial 96 finished with value: 0.08481570643590615 and parameters: {'num_leaves': 36, 'learning_rate': 0.001989125497160318, 'n_estimators': 658, 'min_child_samples': 32}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:31:55,401] Trial 97 finished with value: 0.07722460770836949 and parameters: {'num_leaves': 56, 'learning_rate': 0.0017467446908031859, 'n_estimators': 800, 'min_child_samples': 18}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:32:07,155] Trial 98 finished with value: 0.0 and parameters: {'num_leaves': 47, 'learning_rate': 0.0010074636618077584, 'n_estimators': 783, 'min_child_samples': 13}. Best is trial 80 with value: 0.17101851851851854.\n",
      "[I 2023-08-01 22:32:16,179] Trial 99 finished with value: 0.15481137110492219 and parameters: {'num_leaves': 30, 'learning_rate': 0.0014723489255011825, 'n_estimators': 694, 'min_child_samples': 9}. Best is trial 80 with value: 0.17101851851851854.\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=42)  # Optuna sampler (Tree-structured Parzen Estimator)\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "study.optimize(objective, n_trials=100)  # You can adjust the number of trials as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "279a47d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4354, number of negative: 135646\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 140000, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031100 -> initscore=-3.438954\n",
      "[LightGBM] [Info] Start training from score -3.438954\n"
     ]
    }
   ],
   "source": [
    "params = study.best_params\n",
    "params['scale_pos_weight'] = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "model_new = lgb.LGBMClassifier(**params)\n",
    "model_new.fit(X_train_pca, y_train)\n",
    "y_pred_new = model_new.predict(X_val_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc4cf4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9657142857142857\n",
      "Precision: 0.0949367088607595\n",
      "Recall: 0.013992537313432836\n",
      "F1 Score: 0.024390243902439025\n",
      "ROC AUC Score: 0.5048888647425452\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred_new))\n",
    "print(\"Precision:\", precision_score(y_val, y_pred_new))\n",
    "print(\"Recall:\", recall_score(y_val, y_pred_new))\n",
    "print(\"F1 Score:\", f1_score(y_val, y_pred_new))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_val, y_pred_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cbace48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective2(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs': -1,\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log = True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),\n",
    "        'scale_pos_weight': len(y_train[y_train == 0]) / len(y_train[y_train == 1])        \n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "\n",
    "    # Use cross-validation to evaluate the model's performance\n",
    "    score = cross_val_score(model, X_train_pca, y_train, n_jobs=-1, cv=3, scoring='recall').mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99324c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-01 22:33:49,088] A new study created in memory with name: no-name-31055935-aa8e-433b-b2a8-ff8a76f7f5e9\n",
      "[I 2023-08-01 22:33:56,618] Trial 0 finished with value: 0.13550785722015593 and parameters: {'num_leaves': 44, 'learning_rate': 0.07969454818643935, 'n_estimators': 746, 'min_child_samples': 60}. Best is trial 0 with value: 0.13550785722015593.\n",
      "[I 2023-08-01 22:33:58,405] Trial 1 finished with value: 0.0 and parameters: {'num_leaves': 24, 'learning_rate': 0.002051110418843397, 'n_estimators': 105, 'min_child_samples': 87}. Best is trial 0 with value: 0.13550785722015593.\n",
      "[I 2023-08-01 22:34:00,270] Trial 2 finished with value: 0.37344847510250684 and parameters: {'num_leaves': 64, 'learning_rate': 0.02607024758370768, 'n_estimators': 69, 'min_child_samples': 97}. Best is trial 2 with value: 0.37344847510250684.\n",
      "[I 2023-08-01 22:34:04,970] Trial 3 finished with value: 0.0 and parameters: {'num_leaves': 85, 'learning_rate': 0.0026587543983272706, 'n_estimators': 222, 'min_child_samples': 19}. Best is trial 2 with value: 0.37344847510250684.\n",
      "[I 2023-08-01 22:34:10,150] Trial 4 finished with value: 0.5323870241795183 and parameters: {'num_leaves': 37, 'learning_rate': 0.01120760621186057, 'n_estimators': 460, 'min_child_samples': 30}. Best is trial 4 with value: 0.5323870241795183.\n",
      "[I 2023-08-01 22:34:16,011] Trial 5 finished with value: 0.0 and parameters: {'num_leaves': 65, 'learning_rate': 0.0019010245319870357, 'n_estimators': 327, 'min_child_samples': 37}. Best is trial 4 with value: 0.5323870241795183.\n",
      "[I 2023-08-01 22:34:19,596] Trial 6 finished with value: 0.4251249415399531 and parameters: {'num_leaves': 51, 'learning_rate': 0.037183641805732096, 'n_estimators': 239, 'min_child_samples': 52}. Best is trial 4 with value: 0.5323870241795183.\n",
      "[I 2023-08-01 22:34:31,296] Trial 7 finished with value: 0.0 and parameters: {'num_leaves': 63, 'learning_rate': 0.001238513729886093, 'n_estimators': 627, 'min_child_samples': 18}. Best is trial 4 with value: 0.5323870241795183.\n",
      "[I 2023-08-01 22:34:37,660] Trial 8 finished with value: 0.3024778199892541 and parameters: {'num_leaves': 15, 'learning_rate': 0.07902619549708234, 'n_estimators': 968, 'min_child_samples': 81}. Best is trial 4 with value: 0.5323870241795183.\n",
      "[I 2023-08-01 22:34:46,555] Trial 9 finished with value: 0.02939867948326065 and parameters: {'num_leaves': 37, 'learning_rate': 0.0015679933916723015, 'n_estimators': 700, 'min_child_samples': 45}. Best is trial 4 with value: 0.5323870241795183.\n",
      "[I 2023-08-01 22:34:55,251] Trial 10 finished with value: 0.39733577235926715 and parameters: {'num_leaves': 96, 'learning_rate': 0.006051704343080744, 'n_estimators': 458, 'min_child_samples': 2}. Best is trial 4 with value: 0.5323870241795183.\n",
      "[I 2023-08-01 22:35:00,225] Trial 11 finished with value: 0.47933188156231826 and parameters: {'num_leaves': 43, 'learning_rate': 0.016983285013368467, 'n_estimators': 433, 'min_child_samples': 63}. Best is trial 4 with value: 0.5323870241795183.\n",
      "[I 2023-08-01 22:35:04,874] Trial 12 finished with value: 0.5610984223539828 and parameters: {'num_leaves': 31, 'learning_rate': 0.011302749714476855, 'n_estimators': 429, 'min_child_samples': 66}. Best is trial 12 with value: 0.5610984223539828.\n",
      "[I 2023-08-01 22:35:20,020] Trial 13 finished with value: 0.5748788555943496 and parameters: {'num_leaves': 27, 'learning_rate': 0.007566526068291984, 'n_estimators': 549, 'min_child_samples': 32}. Best is trial 13 with value: 0.5748788555943496.\n",
      "[I 2023-08-01 22:35:32,455] Trial 14 finished with value: 0.6185178962103967 and parameters: {'num_leaves': 11, 'learning_rate': 0.006687589349471751, 'n_estimators': 597, 'min_child_samples': 69}. Best is trial 14 with value: 0.6185178962103967.\n",
      "[I 2023-08-01 22:35:40,801] Trial 15 finished with value: 0.6102496362661766 and parameters: {'num_leaves': 15, 'learning_rate': 0.004913460742665329, 'n_estimators': 878, 'min_child_samples': 79}. Best is trial 14 with value: 0.6185178962103967.\n",
      "[I 2023-08-01 22:35:49,505] Trial 16 finished with value: 0.6139247876294427 and parameters: {'num_leaves': 12, 'learning_rate': 0.003889093079655196, 'n_estimators': 978, 'min_child_samples': 79}. Best is trial 14 with value: 0.6185178962103967.\n",
      "[I 2023-08-01 22:35:57,999] Trial 17 finished with value: 0.5875114467777834 and parameters: {'num_leaves': 17, 'learning_rate': 0.0040768786336277466, 'n_estimators': 833, 'min_child_samples': 72}. Best is trial 14 with value: 0.6185178962103967.\n",
      "[I 2023-08-01 22:36:06,823] Trial 18 finished with value: 0.5774066395424706 and parameters: {'num_leaves': 12, 'learning_rate': 0.003041654393076625, 'n_estimators': 997, 'min_child_samples': 100}. Best is trial 14 with value: 0.6185178962103967.\n",
      "[I 2023-08-01 22:36:24,467] Trial 19 finished with value: 0.45107867092705134 and parameters: {'num_leaves': 76, 'learning_rate': 0.003642907866333236, 'n_estimators': 822, 'min_child_samples': 89}. Best is trial 14 with value: 0.6185178962103967.\n",
      "[I 2023-08-01 22:36:31,346] Trial 20 finished with value: 0.5822286836790941 and parameters: {'num_leaves': 23, 'learning_rate': 0.006849922933368837, 'n_estimators': 581, 'min_child_samples': 54}. Best is trial 14 with value: 0.6185178962103967.\n",
      "[I 2023-08-01 22:36:38,819] Trial 21 finished with value: 0.6111687009813692 and parameters: {'num_leaves': 11, 'learning_rate': 0.004056625126103098, 'n_estimators': 870, 'min_child_samples': 76}. Best is trial 14 with value: 0.6185178962103967.\n",
      "[I 2023-08-01 22:36:46,381] Trial 22 finished with value: 0.6212735082166821 and parameters: {'num_leaves': 11, 'learning_rate': 0.004478455388836282, 'n_estimators': 894, 'min_child_samples': 72}. Best is trial 22 with value: 0.6212735082166821.\n",
      "[I 2023-08-01 22:36:54,521] Trial 23 finished with value: 0.586591432779015 and parameters: {'num_leaves': 22, 'learning_rate': 0.00550144005684098, 'n_estimators': 721, 'min_child_samples': 69}. Best is trial 22 with value: 0.6212735082166821.\n",
      "[I 2023-08-01 22:37:02,666] Trial 24 finished with value: 0.00022972662531587412 and parameters: {'num_leaves': 10, 'learning_rate': 0.0010630804852256052, 'n_estimators': 902, 'min_child_samples': 89}. Best is trial 22 with value: 0.6212735082166821.\n",
      "[I 2023-08-01 22:37:13,629] Trial 25 finished with value: 0.43155807811844404 and parameters: {'num_leaves': 34, 'learning_rate': 0.0025488827377413204, 'n_estimators': 783, 'min_child_samples': 59}. Best is trial 22 with value: 0.6212735082166821.\n",
      "[I 2023-08-01 22:37:22,824] Trial 26 finished with value: 0.5757969710259666 and parameters: {'num_leaves': 20, 'learning_rate': 0.007756193022802545, 'n_estimators': 931, 'min_child_samples': 45}. Best is trial 22 with value: 0.6212735082166821.\n",
      "[I 2023-08-01 22:37:31,351] Trial 27 finished with value: 0.535373628522554 and parameters: {'num_leaves': 30, 'learning_rate': 0.004488657824161801, 'n_estimators': 654, 'min_child_samples': 84}. Best is trial 22 with value: 0.6212735082166821.\n",
      "[I 2023-08-01 22:37:43,875] Trial 28 finished with value: 0.5169981881340818 and parameters: {'num_leaves': 44, 'learning_rate': 0.0033411133046600205, 'n_estimators': 938, 'min_child_samples': 74}. Best is trial 22 with value: 0.6212735082166821.\n",
      "[I 2023-08-01 22:37:50,667] Trial 29 finished with value: 0.5875112885638543 and parameters: {'num_leaves': 19, 'learning_rate': 0.008680325412909053, 'n_estimators': 780, 'min_child_samples': 61}. Best is trial 22 with value: 0.6212735082166821.\n",
      "[I 2023-08-01 22:38:01,145] Trial 30 finished with value: 0.5029859714873185 and parameters: {'num_leaves': 51, 'learning_rate': 0.006033594619575193, 'n_estimators': 717, 'min_child_samples': 69}. Best is trial 22 with value: 0.6212735082166821.\n",
      "[I 2023-08-01 22:38:08,107] Trial 31 finished with value: 0.6134645433091646 and parameters: {'num_leaves': 12, 'learning_rate': 0.00445181990151034, 'n_estimators': 858, 'min_child_samples': 77}. Best is trial 22 with value: 0.6212735082166821.\n",
      "[I 2023-08-01 22:38:17,899] Trial 32 finished with value: 0.4033069242642578 and parameters: {'num_leaves': 25, 'learning_rate': 0.0021726099729111217, 'n_estimators': 828, 'min_child_samples': 94}. Best is trial 22 with value: 0.6212735082166821.\n",
      "[I 2023-08-01 22:38:26,015] Trial 33 finished with value: 0.5879712164562738 and parameters: {'num_leaves': 11, 'learning_rate': 0.003035919327928525, 'n_estimators': 999, 'min_child_samples': 80}. Best is trial 22 with value: 0.6212735082166821.\n",
      "[I 2023-08-01 22:38:33,866] Trial 34 finished with value: 0.6019826420333908 and parameters: {'num_leaves': 18, 'learning_rate': 0.004743284105208984, 'n_estimators': 909, 'min_child_samples': 91}. Best is trial 22 with value: 0.6212735082166821.\n",
      "[I 2023-08-01 22:38:41,971] Trial 35 finished with value: 0.32176852795861627 and parameters: {'num_leaves': 25, 'learning_rate': 0.0024448870645142695, 'n_estimators': 642, 'min_child_samples': 75}. Best is trial 22 with value: 0.6212735082166821.\n",
      "[I 2023-08-01 22:38:47,264] Trial 36 finished with value: 0.6244892063293166 and parameters: {'num_leaves': 10, 'learning_rate': 0.01021947421435866, 'n_estimators': 767, 'min_child_samples': 57}. Best is trial 36 with value: 0.6244892063293166.\n",
      "[I 2023-08-01 22:38:54,928] Trial 37 finished with value: 0.5360626501845723 and parameters: {'num_leaves': 29, 'learning_rate': 0.008734978590004104, 'n_estimators': 767, 'min_child_samples': 56}. Best is trial 36 with value: 0.6244892063293166.\n",
      "[I 2023-08-01 22:38:58,272] Trial 38 finished with value: 0.6074941824738204 and parameters: {'num_leaves': 16, 'learning_rate': 0.012066687689343615, 'n_estimators': 351, 'min_child_samples': 46}. Best is trial 36 with value: 0.6244892063293166.\n",
      "[I 2023-08-01 22:39:04,313] Trial 39 finished with value: 0.5006893380898769 and parameters: {'num_leaves': 39, 'learning_rate': 0.014294959625414301, 'n_estimators': 503, 'min_child_samples': 65}. Best is trial 36 with value: 0.6244892063293166.\n",
      "[I 2023-08-01 22:39:10,494] Trial 40 finished with value: 0.5976189436498941 and parameters: {'num_leaves': 20, 'learning_rate': 0.006619024268572926, 'n_estimators': 688, 'min_child_samples': 84}. Best is trial 36 with value: 0.6244892063293166.\n",
      "[I 2023-08-01 22:39:17,014] Trial 41 finished with value: 0.624948976007807 and parameters: {'num_leaves': 10, 'learning_rate': 0.00525767003365846, 'n_estimators': 842, 'min_child_samples': 70}. Best is trial 41 with value: 0.624948976007807.\n",
      "[I 2023-08-01 22:39:23,936] Trial 42 finished with value: 0.629312990819162 and parameters: {'num_leaves': 10, 'learning_rate': 0.005534948761506561, 'n_estimators': 950, 'min_child_samples': 70}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:39:30,404] Trial 43 finished with value: 0.60083211033966 and parameters: {'num_leaves': 16, 'learning_rate': 0.009067471368184029, 'n_estimators': 792, 'min_child_samples': 50}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:39:40,589] Trial 44 finished with value: 0.46118537672951554 and parameters: {'num_leaves': 72, 'learning_rate': 0.005571699863336441, 'n_estimators': 591, 'min_child_samples': 69}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:39:42,117] Trial 45 finished with value: 0.0 and parameters: {'num_leaves': 10, 'learning_rate': 0.006379698120168489, 'n_estimators': 128, 'min_child_samples': 60}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:39:54,263] Trial 46 finished with value: 0.38447203062515384 and parameters: {'num_leaves': 59, 'learning_rate': 0.0102094421596195, 'n_estimators': 944, 'min_child_samples': 40}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:40:08,854] Trial 47 finished with value: 0.19407343278028075 and parameters: {'num_leaves': 94, 'learning_rate': 0.018321458565122146, 'n_estimators': 887, 'min_child_samples': 57}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:40:15,708] Trial 48 finished with value: 0.5826860801486452 and parameters: {'num_leaves': 22, 'learning_rate': 0.0075885042574940975, 'n_estimators': 754, 'min_child_samples': 65}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:40:21,447] Trial 49 finished with value: 0.6031293765928187 and parameters: {'num_leaves': 14, 'learning_rate': 0.005437101206816027, 'n_estimators': 671, 'min_child_samples': 71}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:40:30,080] Trial 50 finished with value: 0.4915054941369082 and parameters: {'num_leaves': 33, 'learning_rate': 0.010397911515194827, 'n_estimators': 831, 'min_child_samples': 51}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:40:38,085] Trial 51 finished with value: 0.6019813763219565 and parameters: {'num_leaves': 14, 'learning_rate': 0.003668162694244869, 'n_estimators': 967, 'min_child_samples': 83}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:40:44,850] Trial 52 finished with value: 0.6272460840470364 and parameters: {'num_leaves': 10, 'learning_rate': 0.004978276249632075, 'n_estimators': 948, 'min_child_samples': 64}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:40:52,612] Trial 53 finished with value: 0.604278009719398 and parameters: {'num_leaves': 18, 'learning_rate': 0.0050260329442661685, 'n_estimators': 857, 'min_child_samples': 64}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:41:00,049] Trial 54 finished with value: 0.5654637028767723 and parameters: {'num_leaves': 10, 'learning_rate': 0.0029528306940990586, 'n_estimators': 935, 'min_child_samples': 68}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:41:06,456] Trial 55 finished with value: 0.6113981111788267 and parameters: {'num_leaves': 15, 'learning_rate': 0.007024787012102433, 'n_estimators': 804, 'min_child_samples': 72}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:41:16,076] Trial 56 finished with value: 0.5762559496348106 and parameters: {'num_leaves': 25, 'learning_rate': 0.004254424494041686, 'n_estimators': 902, 'min_child_samples': 63}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:41:22,381] Trial 57 finished with value: 0.6113968454673924 and parameters: {'num_leaves': 14, 'learning_rate': 0.005571500206729865, 'n_estimators': 740, 'min_child_samples': 3}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:41:31,831] Trial 58 finished with value: 0.5753384670589107 and parameters: {'num_leaves': 21, 'learning_rate': 0.0034032799103793834, 'n_estimators': 968, 'min_child_samples': 54}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:41:36,095] Trial 59 finished with value: 0.545251556983278 and parameters: {'num_leaves': 27, 'learning_rate': 0.008020968085509875, 'n_estimators': 356, 'min_child_samples': 59}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:41:41,934] Trial 60 finished with value: 0.5670713146121955 and parameters: {'num_leaves': 18, 'learning_rate': 0.004931776008368899, 'n_estimators': 606, 'min_child_samples': 73}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:41:50,269] Trial 61 finished with value: 0.6095604563902289 and parameters: {'num_leaves': 13, 'learning_rate': 0.0038055747509355775, 'n_estimators': 1000, 'min_child_samples': 79}. Best is trial 42 with value: 0.629312990819162.\n",
      "[I 2023-08-01 22:41:57,518] Trial 62 finished with value: 0.6297729187115816 and parameters: {'num_leaves': 10, 'learning_rate': 0.005947146053158111, 'n_estimators': 957, 'min_child_samples': 76}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:42:03,913] Trial 63 finished with value: 0.6279358967787011 and parameters: {'num_leaves': 10, 'learning_rate': 0.00650362243454204, 'n_estimators': 874, 'min_child_samples': 67}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:42:09,983] Trial 64 finished with value: 0.6286246020128609 and parameters: {'num_leaves': 10, 'learning_rate': 0.006306745770503014, 'n_estimators': 865, 'min_child_samples': 67}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:42:17,228] Trial 65 finished with value: 0.6033594196459933 and parameters: {'num_leaves': 17, 'learning_rate': 0.006502455418072713, 'n_estimators': 847, 'min_child_samples': 67}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:42:23,378] Trial 66 finished with value: 0.6159915361876392 and parameters: {'num_leaves': 10, 'learning_rate': 0.009327118609132896, 'n_estimators': 929, 'min_child_samples': 63}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:42:30,774] Trial 67 finished with value: 0.6141532485433244 and parameters: {'num_leaves': 14, 'learning_rate': 0.0075550799936226175, 'n_estimators': 878, 'min_child_samples': 47}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:42:44,901] Trial 68 finished with value: 0.487598242939387 and parameters: {'num_leaves': 49, 'learning_rate': 0.005976072784455122, 'n_estimators': 961, 'min_child_samples': 75}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:42:52,535] Trial 69 finished with value: 0.5870508860296467 and parameters: {'num_leaves': 22, 'learning_rate': 0.005058287750080406, 'n_estimators': 810, 'min_child_samples': 61}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:43:08,597] Trial 70 finished with value: 0.35599273228494455 and parameters: {'num_leaves': 86, 'learning_rate': 0.008230688369052984, 'n_estimators': 921, 'min_child_samples': 55}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:43:15,592] Trial 71 finished with value: 0.6189776658888869 and parameters: {'num_leaves': 10, 'learning_rate': 0.004328626379554416, 'n_estimators': 889, 'min_child_samples': 72}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:43:22,036] Trial 72 finished with value: 0.6240300695065434 and parameters: {'num_leaves': 12, 'learning_rate': 0.006076993140139109, 'n_estimators': 854, 'min_child_samples': 78}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:43:28,504] Trial 73 finished with value: 0.6162207881711672 and parameters: {'num_leaves': 13, 'learning_rate': 0.007134260003439351, 'n_estimators': 857, 'min_child_samples': 78}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:43:36,299] Trial 74 finished with value: 0.6058864125244678 and parameters: {'num_leaves': 17, 'learning_rate': 0.005876090330673585, 'n_estimators': 913, 'min_child_samples': 82}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:43:43,343] Trial 75 finished with value: 0.620585119410381 and parameters: {'num_leaves': 13, 'learning_rate': 0.006507765082488066, 'n_estimators': 954, 'min_child_samples': 66}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:43:51,095] Trial 76 finished with value: 0.5946313900232828 and parameters: {'num_leaves': 20, 'learning_rate': 0.004828289774277488, 'n_estimators': 836, 'min_child_samples': 86}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:43:58,642] Trial 77 finished with value: 0.5815401366588636 and parameters: {'num_leaves': 16, 'learning_rate': 0.009574306248034004, 'n_estimators': 981, 'min_child_samples': 76}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:44:05,912] Trial 78 finished with value: 0.601063577318198 and parameters: {'num_leaves': 12, 'learning_rate': 0.00392577602064815, 'n_estimators': 873, 'min_child_samples': 70}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:44:12,412] Trial 79 finished with value: 0.5916447856802471 and parameters: {'num_leaves': 19, 'learning_rate': 0.008201941603166108, 'n_estimators': 735, 'min_child_samples': 87}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:44:17,711] Trial 80 finished with value: 0.6132348166838487 and parameters: {'num_leaves': 10, 'learning_rate': 0.011649192030250909, 'n_estimators': 803, 'min_child_samples': 67}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:44:24,510] Trial 81 finished with value: 0.6231113212192092 and parameters: {'num_leaves': 12, 'learning_rate': 0.005424226226956354, 'n_estimators': 904, 'min_child_samples': 58}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:44:31,476] Trial 82 finished with value: 0.6148430612749891 and parameters: {'num_leaves': 15, 'learning_rate': 0.005910476966836433, 'n_estimators': 899, 'min_child_samples': 58}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:44:37,440] Trial 83 finished with value: 0.6166808742775162 and parameters: {'num_leaves': 12, 'learning_rate': 0.005318471953973873, 'n_estimators': 769, 'min_child_samples': 62}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:44:45,991] Trial 84 finished with value: 0.5721218196627006 and parameters: {'num_leaves': 23, 'learning_rate': 0.006986600703102692, 'n_estimators': 869, 'min_child_samples': 49}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:44:53,745] Trial 85 finished with value: 0.6058867289523263 and parameters: {'num_leaves': 16, 'learning_rate': 0.004658765710870019, 'n_estimators': 938, 'min_child_samples': 54}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:45:00,751] Trial 86 finished with value: 0.6205843283407345 and parameters: {'num_leaves': 12, 'learning_rate': 0.006327806520649496, 'n_estimators': 980, 'min_child_samples': 39}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:45:06,844] Trial 87 finished with value: 0.6249496088635241 and parameters: {'num_leaves': 10, 'learning_rate': 0.005447336711620154, 'n_estimators': 820, 'min_child_samples': 75}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:45:14,621] Trial 88 finished with value: 0.5882006266537311 and parameters: {'num_leaves': 19, 'learning_rate': 0.004337805203507257, 'n_estimators': 821, 'min_child_samples': 75}. Best is trial 62 with value: 0.6297729187115816.\n",
      "[I 2023-08-01 22:45:20,139] Trial 89 finished with value: 0.6306910341431989 and parameters: {'num_leaves': 10, 'learning_rate': 0.007480367533288891, 'n_estimators': 784, 'min_child_samples': 80}. Best is trial 89 with value: 0.6306910341431989.\n",
      "[I 2023-08-01 22:45:32,568] Trial 90 finished with value: 0.43224551764116953 and parameters: {'num_leaves': 68, 'learning_rate': 0.0075821600163063635, 'n_estimators': 786, 'min_child_samples': 80}. Best is trial 89 with value: 0.6306910341431989.\n",
      "[I 2023-08-01 22:45:38,470] Trial 91 finished with value: 0.6238009757369447 and parameters: {'num_leaves': 10, 'learning_rate': 0.008752417484991438, 'n_estimators': 848, 'min_child_samples': 78}. Best is trial 89 with value: 0.6306910341431989.\n",
      "[I 2023-08-01 22:45:44,781] Trial 92 finished with value: 0.6136955356459147 and parameters: {'num_leaves': 15, 'learning_rate': 0.007144613694533832, 'n_estimators': 765, 'min_child_samples': 92}. Best is trial 89 with value: 0.6306910341431989.\n",
      "[I 2023-08-01 22:45:50,789] Trial 93 finished with value: 0.6162209463850965 and parameters: {'num_leaves': 13, 'learning_rate': 0.006209491365717418, 'n_estimators': 706, 'min_child_samples': 69}. Best is trial 89 with value: 0.6306910341431989.\n",
      "[I 2023-08-01 22:45:56,688] Trial 94 finished with value: 0.6254081128305801 and parameters: {'num_leaves': 10, 'learning_rate': 0.005177082523285679, 'n_estimators': 828, 'min_child_samples': 73}. Best is trial 89 with value: 0.6306910341431989.\n",
      "[I 2023-08-01 22:46:04,316] Trial 95 finished with value: 0.6022106283054846 and parameters: {'num_leaves': 17, 'learning_rate': 0.00515838977662546, 'n_estimators': 819, 'min_child_samples': 73}. Best is trial 89 with value: 0.6306910341431989.\n",
      "[I 2023-08-01 22:46:11,162] Trial 96 finished with value: 0.6132351331117073 and parameters: {'num_leaves': 10, 'learning_rate': 0.0040246561850849055, 'n_estimators': 922, 'min_child_samples': 71}. Best is trial 89 with value: 0.6306910341431989.\n",
      "[I 2023-08-01 22:46:17,955] Trial 97 finished with value: 0.536293326093464 and parameters: {'num_leaves': 15, 'learning_rate': 0.003461840979116825, 'n_estimators': 729, 'min_child_samples': 66}. Best is trial 89 with value: 0.6306910341431989.\n",
      "[I 2023-08-01 22:46:25,718] Trial 98 finished with value: 0.5870526263828689 and parameters: {'num_leaves': 21, 'learning_rate': 0.004798461319377522, 'n_estimators': 791, 'min_child_samples': 81}. Best is trial 89 with value: 0.6306910341431989.\n",
      "[I 2023-08-01 22:46:36,240] Trial 99 finished with value: 0.46049730435107294 and parameters: {'num_leaves': 41, 'learning_rate': 0.00983024778818673, 'n_estimators': 953, 'min_child_samples': 64}. Best is trial 89 with value: 0.6306910341431989.\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=42)  # Optuna sampler (Tree-structured Parzen Estimator)\n",
    "study2 = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "study2.optimize(objective2, n_trials=100)  # You can adjust the number of trials as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "426ae76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4354, number of negative: 135646\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 140000, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031100 -> initscore=-3.438954\n",
      "[LightGBM] [Info] Start training from score -3.438954\n"
     ]
    }
   ],
   "source": [
    "params2 = study2.best_params\n",
    "params2['scale_pos_weight'] = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "model_new2 = lgb.LGBMClassifier(**params2)\n",
    "model_new2.fit(X_train_pca, y_train)\n",
    "y_pred_new2 = model_new2.predict(X_val_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bf62984",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6215428571428572\n",
      "Precision: 0.04971149578339991\n",
      "Recall: 0.6268656716417911\n",
      "F1 Score: 0.09211788896504454\n",
      "ROC AUC Score: 0.6241201737129022\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred_new2))\n",
    "print(\"Precision:\", precision_score(y_val, y_pred_new2))\n",
    "print(\"Recall:\", recall_score(y_val, y_pred_new2))\n",
    "print(\"F1 Score:\", f1_score(y_val, y_pred_new2))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_val, y_pred_new2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85a5a9c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.609\n",
      "Precision: 0.04665372726619222\n",
      "Recall: 0.605410447761194\n",
      "F1 Score: 0.08663151571781351\n",
      "ROC AUC Score: 0.6072619322041056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_model = LogisticRegression(class_weight='balanced')\n",
    "logreg_model.fit(X_train_pca, y_train)\n",
    "\n",
    "logreg_predictions = logreg_model.predict(X_val_pca)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, logreg_predictions))\n",
    "print(\"Precision:\", precision_score(y_val, logreg_predictions))\n",
    "print(\"Recall:\", recall_score(y_val, logreg_predictions))\n",
    "print(\"F1 Score:\", f1_score(y_val, logreg_predictions))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_val, logreg_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f2777bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective3(trial):\n",
    "    params = {\n",
    "        'objective': 'binary:hinge',  \n",
    "        'eta': trial.suggest_float('eta', 0.001, 0.1, log=True),  \n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 0.1, 10, log=True),\n",
    "        'gamma': trial.suggest_float('gamma', 0.001, 1, log=True),  \n",
    "        'subsample': trial.suggest_float('subsample', 0.1, 1),  \n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1),\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train_pca, label=y_train)\n",
    "\n",
    "    # Train the model with the suggested hyperparameters\n",
    "    num_rounds = 100\n",
    "    model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    dtest = xgb.DMatrix(X_val_pca)\n",
    "    y_pred = model.predict(dtest)\n",
    "\n",
    "    # Convert predicted labels from float to int\n",
    "    y_pred = y_pred.astype(int)\n",
    "\n",
    "    # Calculate precision\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "\n",
    "    # Optuna aims to minimize the objective function, so return the negative precision\n",
    "    return -recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15ee3d58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-01 23:34:58,590] A new study created in memory with name: no-name-6e52a299-93e1-4e6d-bf84-38d16e1e6c74\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d192f1da3924d58bf769771fdfa5c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-08-01 23:35:03,379] Trial 0 finished with value: -0.0 and parameters: {'eta': 0.09206953955933338, 'max_depth': 4, 'min_child_weight': 5.680080942740105, 'gamma': 0.24073129453894002, 'subsample': 0.4631828466537756, 'colsample_bytree': 0.5070734326362988}. Best is trial 0 with value: -0.0.\n",
      "[I 2023-08-01 23:35:06,656] Trial 1 finished with value: -1.0 and parameters: {'eta': 0.0019769292421800712, 'max_depth': 3, 'min_child_weight': 7.396540934305601, 'gamma': 0.10517333701276899, 'subsample': 0.6002967643105485, 'colsample_bytree': 0.35240435898152556}. Best is trial 1 with value: -1.0.\n",
      "[I 2023-08-01 23:35:10,952] Trial 2 finished with value: -1.0 and parameters: {'eta': 0.001616637677407731, 'max_depth': 3, 'min_child_weight': 8.393711738725088, 'gamma': 0.4895593272062752, 'subsample': 0.36263473416873415, 'colsample_bytree': 0.8771562559258164}. Best is trial 1 with value: -1.0.\n",
      "[I 2023-08-01 23:35:24,714] Trial 3 finished with value: -1.0 and parameters: {'eta': 0.0011778105126679433, 'max_depth': 7, 'min_child_weight': 0.6402828516650968, 'gamma': 0.005300106606322117, 'subsample': 0.821578463165458, 'colsample_bytree': 0.7365849620047185}. Best is trial 1 with value: -1.0.\n",
      "[I 2023-08-01 23:35:31,016] Trial 4 finished with value: -0.0 and parameters: {'eta': 0.034442298254518555, 'max_depth': 7, 'min_child_weight': 2.1033723775121955, 'gamma': 0.3666062120003387, 'subsample': 0.21520169941874245, 'colsample_bytree': 0.5286796003553493}. Best is trial 1 with value: -1.0.\n",
      "[I 2023-08-01 23:35:38,271] Trial 5 finished with value: -0.0 and parameters: {'eta': 0.055641875851971986, 'max_depth': 4, 'min_child_weight': 0.1850491896487031, 'gamma': 0.021728547397933937, 'subsample': 0.7257998399855725, 'colsample_bytree': 0.7091869692172251}. Best is trial 1 with value: -1.0.\n",
      "[I 2023-08-01 23:35:42,846] Trial 6 finished with value: -0.0 and parameters: {'eta': 0.04203393088543297, 'max_depth': 5, 'min_child_weight': 0.13901244961785023, 'gamma': 0.0010524613383593715, 'subsample': 0.5541533282335585, 'colsample_bytree': 0.2622630043375521}. Best is trial 1 with value: -1.0.\n",
      "[I 2023-08-01 23:35:47,301] Trial 7 finished with value: -0.0 and parameters: {'eta': 0.03277989167742038, 'max_depth': 7, 'min_child_weight': 0.7522674707066641, 'gamma': 0.0010498698462184158, 'subsample': 0.8242612844049579, 'colsample_bytree': 0.12660192373311122}. Best is trial 1 with value: -1.0.\n",
      "[I 2023-08-01 23:36:00,032] Trial 8 finished with value: -1.0 and parameters: {'eta': 0.004545806307868488, 'max_depth': 6, 'min_child_weight': 0.42900671660207557, 'gamma': 0.6094904391987206, 'subsample': 0.9332632147841426, 'colsample_bytree': 0.7538614895333621}. Best is trial 1 with value: -1.0.\n",
      "[I 2023-08-01 23:36:12,866] Trial 9 finished with value: -1.0 and parameters: {'eta': 0.0014779275011438467, 'max_depth': 6, 'min_child_weight': 1.0280903185375707, 'gamma': 0.00263841018127123, 'subsample': 0.8368259550350337, 'colsample_bytree': 0.8394444026169418}. Best is trial 1 with value: -1.0.\n"
     ]
    }
   ],
   "source": [
    "study3 = optuna.create_study(direction='minimize')  # Optuna aims to minimize the objective function (negative accuracy)\n",
    "study3.optimize(objective3, n_trials=10, show_progress_bar=True)  # You can adjust the number of trials as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "98839a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "params3 = study3.best_params\n",
    "params3['scale_pos_weight'] = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "model_new3 = xgb.XGBClassifier(**params3)\n",
    "model_new3.fit(X_train_pca, y_train)\n",
    "y_pred_new3 = model_new3.predict(X_val_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a73edf5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6569714285714285\n",
      "Precision: 0.0512967826657912\n",
      "Recall: 0.5830223880597015\n",
      "F1 Score: 0.09429692214846107\n",
      "ROC AUC Score: 0.6211651671493981\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred_new3))\n",
    "print(\"Precision:\", precision_score(y_val, y_pred_new3))\n",
    "print(\"Recall:\", recall_score(y_val, y_pred_new3))\n",
    "print(\"F1 Score:\", f1_score(y_val, y_pred_new3))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_val, y_pred_new3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fc3da2cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7722571428571429\n",
      "Precision: 0.05241987803295705\n",
      "Recall: 0.376865671641791\n",
      "F1 Score: 0.0920378175190796\n",
      "ROC AUC Score: 0.5808078652950762\n"
     ]
    }
   ],
   "source": [
    "model_new4 = xgb.XGBClassifier(scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1]))\n",
    "model_new4.fit(X_train_pca, y_train)\n",
    "y_pred_new4 = model_new4.predict(X_val_pca)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred_new4))\n",
    "print(\"Precision:\", precision_score(y_val, y_pred_new4))\n",
    "print(\"Recall:\", recall_score(y_val, y_pred_new4))\n",
    "print(\"F1 Score:\", f1_score(y_val, y_pred_new4))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_val, y_pred_new4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "78da6942",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4354, number of negative: 135646\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 140000, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031100 -> initscore=-3.438954\n",
      "[LightGBM] [Info] Start training from score -3.438954\n",
      "Accuracy: 0.6821714285714285\n",
      "Precision: 0.051970048136922804\n",
      "Recall: 0.5438432835820896\n",
      "F1 Score: 0.09487388120423107\n",
      "ROC AUC Score: 0.6151926863560059\n"
     ]
    }
   ],
   "source": [
    "model_new5 = lgb.LGBMClassifier(scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1]))\n",
    "model_new5.fit(X_train_pca, y_train)\n",
    "y_pred_new5 = model_new5.predict(X_val_pca)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred_new5))\n",
    "print(\"Precision:\", precision_score(y_val, y_pred_new5))\n",
    "print(\"Recall:\", recall_score(y_val, y_pred_new5))\n",
    "print(\"F1 Score:\", f1_score(y_val, y_pred_new5))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_val, y_pred_new5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8722782b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6283428571428571\n",
      "Precision: 0.048084204149628954\n",
      "Recall: 0.5923507462686567\n",
      "F1 Score: 0.0889480319372461\n",
      "ROC AUC Score: 0.6109154108612795\n"
     ]
    }
   ],
   "source": [
    "model_svc = SVC(class_weight='balanced')\n",
    "model_svc.fit(X_train_pca, y_train)\n",
    "svc_pred = model_svc.predict(X_val_pca)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, svc_pred))\n",
    "print(\"Precision:\", precision_score(y_val, svc_pred))\n",
    "print(\"Recall:\", recall_score(y_val, svc_pred))\n",
    "print(\"F1 Score:\", f1_score(y_val, svc_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_val, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7d15e3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4354, number of negative: 135646\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 140000, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031100 -> initscore=-3.438954\n",
      "[LightGBM] [Info] Start training from score -3.438954\n",
      "[LightGBM] [Info] Number of positive: 4354, number of negative: 135646\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 140000, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031100 -> initscore=-3.438954\n",
      "[LightGBM] [Info] Start training from score -3.438954\n",
      "[LightGBM] [Info] Number of positive: 4354, number of negative: 135646\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 140000, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031100 -> initscore=-3.438954\n",
      "[LightGBM] [Info] Start training from score -3.438954\n"
     ]
    }
   ],
   "source": [
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[('model1', model_new), ('model2', model_new2), ('rf', rf), ('logreg_model', logreg_model), ('model3', model_new3), ('model4', model_new4), ('model5', model_new5)],\n",
    "    voting='soft'  # 'soft' for probabilities-based voting, 'hard' for majority voting\n",
    ")\n",
    "ensemble_model.fit(X_train_pca, y_train)\n",
    "ensemble_predictions = ensemble_model.predict(X_val_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cafb42ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8942571428571429\n",
      "Precision: 0.07719523962688968\n",
      "Recall: 0.22388059701492538\n",
      "F1 Score: 0.11480507055728296\n",
      "ROC AUC Score: 0.569659586411259\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_val, ensemble_predictions))\n",
    "print(\"Precision:\", precision_score(y_val, ensemble_predictions))\n",
    "print(\"Recall:\", recall_score(y_val, ensemble_predictions))\n",
    "print(\"F1 Score:\", f1_score(y_val, ensemble_predictions))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_val, ensemble_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aac93a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_features.remove('flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "69966689",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = df_test[significant_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ce758049",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaled = scaler.transform(df1)\n",
    "test_final = pca.transform(test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dcdea395",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_ans = ensemble_model.predict(test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "36472575",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"Final_ans.csv\", Final_ans, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79d848d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
